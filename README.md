# Regularisation-acc-fairness-trade-off
This project explores the trade-off between accuracy and fairness in machine learning models to promote equity and inclusivity in automated decision-making. Using logistic regression as the baseline, various methods were implemented:

Standard Model: Evaluates accuracy and fairness using regularization strength.
Fairness-Aware Model: Implements reweighing techniques to balance outcomes for privileged and unprivileged groups.
Combined Model: Optimizes a weighted trade-off between accuracy and fairness.
The results highlight the challenges and opportunities in mitigating biases without significantly compromising performance. Extended analyses include cross-dataset evaluations and proposed directions for future research.
