# Accuracy-Fairness Trade-off in ML Model Selection 
This repository investigates algorithmic fairness in machine learning by comparing standard logistic regression, reweighed logistic regression, and a combined approach that balances accuracy and fairness. The primary metric of fairness is equality of opportunity, measured by the difference in true positive rates between privileged and unprivileged groups. Experiments demonstrate how varying the regularization parameter ùê∂ affects both accuracy and fairness. A combination model is proposed to address the inherent trade-offs, with extended tasks assessing generalisation. Future directions include testing other algorithms, employing additional fairness metrics, and exploring in-processing or post-processing fairness techniques to further refine model performance.
